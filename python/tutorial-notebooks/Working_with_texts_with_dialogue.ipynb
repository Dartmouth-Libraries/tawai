{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Dialogue to Data\n",
    "\n",
    "## Using Computational Text Analysis and Large Language Models for Dialogue-Rich Text Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. OCR: From Image to Digital Text\n",
    "    (Sopranos Pilot, remove OCR layer)\n",
    "2. XML: Adding structure to unstructured text\n",
    "3. NLP / CTA - From Characters to Words: Processing Texts\n",
    "3. XML Parsing\n",
    "3. EDA: Exploratory Data Analysis of Texts: Extracting summary data\n",
    "    (and Visualizations)\n",
    "4. Asking Questions of Texts\n",
    "    (Bechdel test, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OCR/HTR From Image to Digital Text\n",
    "\n",
    "Optical Character Recognition (OCR) is the method used to convert an image of a printed text to a digital text.\n",
    "\n",
    "Options for OCR'ing images of printed text include:\n",
    "\n",
    "1. Proprietary software with Graphical User Interfaces\n",
    "\n",
    "    a. i.e. Abbyy OCR Editor\n",
    "\n",
    "2. Open-source OCR software run using a programming language\n",
    "\n",
    "    a. i.e. using Tesseract with Python\n",
    "\n",
    "3. OCR with LLMs with Vision Capabilities (aka. Vision-Language Models or VLM)\n",
    "\n",
    "    a. GPT-4o(mini), Gemini Flash, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: \n",
    "\n",
    "Upload screenshot image (not pdf with text layer) of screenplay into chat.dartmouth.edu. Write a prompt asking the model (like GPT-4o mini) to transcribe the text for you. Review the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Exercise 1b\n",
    "\n",
    "Review the code below. It uses Tesseract to auto-generate a transcript of an image of a text. Revise this code to OCR or transcribe the same screenshot.\n",
    "\n",
    "Note: for the code below to run, you need to install Tesseract. You can install Tesseract following the directions here: https://tesseract-ocr.github.io/tessdoc/Installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def ocr_image_to_text(image_path):\n",
    "    \"\"\"\n",
    "    Reads an image file and returns the OCR'd transcript of the printed text.\n",
    "    \n",
    "    Args:\n",
    "    image_path (str): The file path to the image to be processed.\n",
    "\n",
    "    Returns:\n",
    "    str: The text extracted from the image.\n",
    "    \"\"\"\n",
    "    # Load the image from the specified file path\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except Exception as e:\n",
    "        return f\"Error opening image file: {e}\"\n",
    "\n",
    "    # Use pytesseract to do OCR on the image\n",
    "    try:\n",
    "        transcript = pytesseract.image_to_string(image)\n",
    "    except Exception as e:\n",
    "        return f\"Error during OCR processing: {e}\"\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def transcribe_multipage_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Reads a PDF file and returns the OCR'd transcript of the printed text.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): The file path to the PDF to be processed.\n",
    "\n",
    "    Returns:\n",
    "    str: The text extracted from the PDF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty string to store the complete transcript\n",
    "    complete_transcript = \"\"\n",
    "\n",
    "    # Open the PDF file\n",
    "    try:\n",
    "        document = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        return f\"Error opening PDF file: {e}\"\n",
    "    \n",
    "    # Process each page in the PDF\n",
    "    for page_number in range(len(document)):\n",
    "        # Get the page\n",
    "        page = document[page_number]\n",
    "        \n",
    "        # Render the page to an image\n",
    "        pix = page.get_pixmap()\n",
    "        \n",
    "        # Convert the pixmap to a PIL image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    # Use pytesseract to do OCR on the image\n",
    "        try:\n",
    "            transcript = pytesseract.image_to_string(img)\n",
    "            complete_transcript += transcript + \"\\n\"  # Append each page's text\n",
    "        except Exception as e:\n",
    "            return f\"Error during OCR processing on page {page_number + 1}: {e}\"\n",
    "\n",
    "    return complete_transcript    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcript1 = transcribe_multipage_pdf(\"../../texts/The Sopranos 101 - Production - Goldenrod Revision - Aug 19 1997.pdf\")\n",
    "#print(len(transcript1))\n",
    "\n",
    "#transcript1[3000:6000]\n",
    "\n",
    "transcript2 = transcribe_multipage_pdf(\"../../texts/image-only_The Sopranos 101 - Production - Goldenrod Revision - Aug 19 1997.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ae sopranos <é-<{? GREEN (REV. 8/07/97)\\nTHE SOPRANOS\\n\\nLOCATIONS\\nINTERIOR EXTERIOR\\nDR. MELFI’S WAITING ROOM ‘SOPRANO\\nDR. MELAY’S OFFICE ‘SOPRANO\\nSOPRANO HC KITCHEN SOPRANO ~ Poon\\n‘SOPRANO FAMILY ROOM STREET/~ 0S/HMO *\\nSOPRANO HOUSE PARKING LOT\\nSOPRANO HOUSE PORK STORE\\nSOPRANO HOUSE \"\\'$ ROOM (pocco\\'s vEesuvro\\n\\n/ BLM PARKWAY/LIVIA\\'S HOUSE\\n\\nBUCCO’S VESUVIO ~ KITC!\\nLIVIA’ S HOUSE\\n\\nCHRIS’ CAR\\n\\nMRI CENTER - MRI MACHINE ROOM\\nTHE PORK STORE\\n\\nTHE PORK STORE - BUTCHERING\\nAIRPORT AREA TOPLESS BAR\\nGREEN GROVE RETIREMENT Ci\\n\\nCONSTRUCTION SITE\\nSTATE PARK\\n\\nPITCH “PUTT\\nBARONE SANITATION\\nMANHATTAN\\n\\nTL GRANAIO\\n\\nCITY PAROCHIAL SCHOOL,\\n\\nTL GRANAIO PLASKIC MOUND\\nCABIN CRUISER - BELOW (AL SCH. BALL COURT *\\nCABIN CRUISER - TOP\\nAPARTMENT BEDROOM\\n\\nCATHEDRAL\\nJUNIOR’ S LINCOLN\\nSOPRANO HOUSE - GARAGE .\\n\\n‘THE SOPRANOS GOLDENROD (REV. 8/19/97)\\n\\n‘THE SOPRANOS\\nFADE IN:\\nINT. DR, MELFI\\'S WAITING ROOM ~ DAY 1\\n\\nTHOMAS SOPRANO, 40, sits and waits. Uneasily. Staring\\nconfusedly at a vaguely erotic Klimpt reproduction. Inner door\\nopens. DR. JENNIFER MELFI (attractive, 35) appears.\\n\\nMELFT\\nMr. Soprano?\\n\\nINT, DR, MELFI\\'S OFFICE - DAY 2\\nMelfi gestures Tommy to a choice of seating.\\n\\nMELFI\\nHave a seat.\\n\\nShe seats herself in a facing armchair. She looks at him with a\\npolite, expectant gaze. He stares back, waiting. There is utter\\nSilence. Nothing happens. Such is psychotherapy. Finally --\\n\\nMELFT\\nMy understanding from your ‘amily\\nphysician, Dr. Cusamano, is you\\ncollapsed? Were unable to breathe?\\nPossibly a panic attack?\\n\\nToor\\n‘They said it was a panic attack --\\nBectuse all the neurological work and\\nblood came back negative. They sent\\nme her\\n\\nMELFI\\nYou don\\'t agree you had a panic attack?\\n\\nHe laughs -- too loud.\\n\\nMELFT\\n\\nHow are you feeling now?\\nTomy\\n\\nNow? Fine. I\\'m back at work.\\nMELFI\\n\\nWhat line of work are you in?\\n\\nToy\\nWaste management consultant.\\n\\n‘THE SOPRANOS GOLDENROD (REV. 8/19/97) aw\\n\\nShe keeps that psychiatric poker-face. Yet there was a reaction.\\nAfter silence...\\n\\nToe\\nLook...it\\'s impossible for me to talk\\nto a psychiatrist.\\n\\n‘THE SOPRANOS GREEN (REV. 8/07/97) 2.\\nMELFT\\nAny thoughts at all on why you\\nblacked out? :\\nTomy shrugs. Fidgets. Then -—\\n\\nMELFI *\\nStress? About what? +\\nDANN 3\\nthe first rays over the post-industrial landscape. *\\nTOMMY (V.0.)\\n\\nWell, I once heard some guy use this\\nsion, \\'The sun setting over the\\n\\nEXT. SOPRANO HOUSE - DAWN 4\\n\\nsplit-level. New Jersey. The only thing distinguishing it from\\nits neighbors is high security fencing and mercury vapor lamps\\n‘that make the lawn bricht enough for night beseball. A sensor\\nfeels the dawn\\'s rays and the lamps switch off and -~\\n\\nINT. SOPRANO HOUSE - BEDROOM - DANN 5\\n‘Toma\\'s EYE\\nslams open from sleep. He stares soberly up at the ceiling.\\n\\nTOMMY (V.0.)\\n‘That morning of the day TI got sick?\\nI\\'d been thinking: it\\'s good to be\\nin a thing from the ground floor. 1\\ncame too late for that, I know. But\\nlately I\\'m getting the feeling T\\n\\nmight be in at the end. That the .\\nbest is over. :\\nEXT. SOPRANO. HOUSE - DAY 6\\n\\nBathrobed Tommy reads his morn'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(transcript2))\n",
    "\n",
    "transcript2[:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XML: Adding structure to unstructured text\n",
    "\n",
    "Traditionally, there were two main ways researchers added xml tags to unstructured texts:\n",
    "\n",
    "1. by manually inserting the tags, often with designated XML editors like OxygenXML.\n",
    "\n",
    "2. programmatically, often using *regular expression* methods. Regular expressions or regexs, allow you to identify different text components by searching for specific text patterns. For example, you could identify footnotes by searching for text lines that begin with numbers followed by a period and a space found near the bottom of a page. The regex for this would look like this: `\"^[0-9]+\\.\\s\\w.*$\"` which can be translated as follows:\n",
    "\n",
    "    + ^ = first character of line\n",
    "    + [0-9]+ matches any number 0-9 that appears 1 or more times (`+`)\n",
    "    + \\. is followed by a period (which needs to be escaped with a back slash as a period is a special wildcard character in reg ex)\n",
    "    + \\w matches any character or number\n",
    "    + .* followed by any character (`.`) appearing 0 or more times (`*`) until the end of the line (`$`).\n",
    "\n",
    "Now, we can use Generative AI tools to do this for us. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. \n",
    "\n",
    "Develop your own prompt or revise and improve the prompt below. Then upload your digitized script to chat.dartmouth.edu and run this prompt.\n",
    "\n",
    "``` \n",
    "Here is the full transcript of __________________________\n",
    "Without adding or changing a single word in this transcript, add xml following TEI guidelines for performance texts. Among other things, this TEI-encoded text should identify different elements of front matter (i.e. <title>, <prologue>, <set>, and <castList> tags), the body text (<div> tags identifying each new scene, <head> tags for the title of each scene, <sp> tags to identify dialogue by each speaker with <speaker> tags tagging each speaker’s name, <l> to identify each line break, <stage> tags to identify stage directions, etc.), and back matter (i.e. <epilogue>). The <sp> tags should identify the name of each speaker, which will help if a particular speaker is implied but not named.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Working with XML text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install beautifulsoup4\n",
    "# %pip install lxml\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../../texts/sopranos-partial.xml\", encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(txt, features=\"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NLP / CTA - From Characters to Words: Processing Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" INT. DR. MELFI'S WAITING ROOM - DAY\\nTHOMAS SOPRANO, 40, sits and waits. Uneasily. Staring confusedly at a vaguely erotic Klimpt reproduction. Inner door opens. DR. JENNIFER MELFI (attractive, 35) appears. MELFI\\nMr. Soprano? INT. DR. MELFI'S OFFICE - DAY\\nMelfi gestures Tommy to a choice of seating. MELFI\\nHave a seat. She seats herself in a facing armchair. She looks at him with a polite, expectant gaze. He stares back, waiting. There is utter silence. Nothing happens. Such is psychotherapy. Finally— MELFI\\nMy understanding from your family physician, Dr. Cusamano, is you collapsed? Were unable to breathe? Possibly a panic attack? TOMMY\\nThey said it was a panic attack — because all the neurological work and blood came back negative. They sent me here. MELFI\\nYou don't agree you had a panic attack? He laughs — too loud. MELFI\\nHow are you feeling now? TOMMY\\nNow? Fine. I'm back at work. MELFI\\nWhat line of work are you in? TOMMY\\nWaste management consultant. She keeps that psychiatric poker-face. Yet there was a reaction. After silence... TOMMY\\nLook...it's impossible for me to talk to a psychiatrist. MELFI\\nAny thoughts at all on why you blacked out? Tommy shrugs. Fidgets. Then — TOMMY\\nI don't know. Stress/ maybe? MELFI\\nStress? About what? EXT. SOPRANO HOUSE - DAWN\\nsplit-level. New Jersey. The only thing distinguishing it from its neighbors is high security fencing and mercury vapor lamps that make the lawn bright enough for night baseball. A sensor reels the dawn's rays and the lamps switch off and — INT. SOPRANO HOUSE - BEDROOM - DAWN\\nTOMMY'S EYE slams open from sleep. He stares soberly up at the ceiling. TOMMY (V.O.)\\nThat morning of the day I got sick? I'd been thinking: it's good to be in a thing from the ground floor. I came too late for that, I know. But lately I'm getting the feeling I might be in at the end. That the best is over. EXT. SOPRANO HOUSE - DAY\\nBathrobed Tommy reads his morning paper in the gated driveway: CLINTON WARNS MEDICARE COULD BE BANKRUPT BY YEAR 2000. Tommy goes to the Sports, ambles down the driveway. MELFI (V.O.)\\nMany Americans, I think, feel this. TOMMY (V.O.)\\nTake my father. He never reached the heights like me. But in ways he had it better. He had his people — they had their standards. They had pride. Today what do we .got? MELFI (V.O.)\\nDid you have this feeling of loss more acutely in the hours before you collapsed? EXT. SOPRANO BACKYARD - DAY\\nAn expanse of lawn, then a pool with Tropitone furniture. Tommy gathers speed, excited. But reaching the pool, he looks around, worried. The water is like glass. The morning is too still. TOMMY (V.O.)\\nI dunno. Couple months before all this these two wild ducks had landed in my pool. Amazing. From Canada or someplace, I don't know. It was mating season. DUCK FAMILY wild mallards, mother and babies, comes waddling from the bushes, QUACKING. Tommy beams, takes feed from a bin and drops down on both knees. He feeds them. TOMMY\\nYum. Yum. INT. SOPRANO HOUSE - KITCHEN - DAY\\nCARMELA SOPRANO (mid 30's), in bathrobe, makes breakfast for her kids. She is a dark-eyed, dark-haired, pretty woman with blonde hi-lites. Hi-lites and nails are a priority. At the table are MEADOW SOPRANO, 15, and her friend, HUNTER SCANGARELO. TOMMY (V.O.)\\nMy daughter's friend was there to drive my daughter, Meadow, to school. HUNTER\\n(staring out window) Meadow, your father with those ducks. CARMELA\\nHave something more than just cran- apple juice, ladies. You need brain food for school. TOMMY JR. enters. He's thirteen. He sits, starts spooning cereal in. Carmela smooches him. Everyone ad-libs happy birthdays. He acknowledges, his mouth crammed with food. HUNTER\\nThe male and female duck just made a home in your pool and 'did it'? Weird. CARMELA\\n(crosses with pastry) Girls, you want some of last night's sfogliatell'? MEADOW\\nGet out of here with that fat. CARMELA\\nOh, have a bite. MEADOW\\nWait — like Italian pastry is brain food? HUNTER\\nBon Jovi? Hello? They laugh. Tommy Jr.'s hand goes in the box; he dunks the Italian pastry in his cereal milk and eats. The girls 'ee-ew'. HUNTER\\nHow do you stay so skinny, Mrs. Soprano? EXT. SOPRANO BACKYARD - POOL - DAY\\nTommy has waded into the pool to adjust a plywood launching ramp he has constructed for the ducks. His robe floats on the water; he doesn't care. He talks to the ducks. TOMMY\\nDon't you worry. I'll make you a better ramp. The ducklings suddenly furiously flap their wings in protoflight, following their mother's lead. TOMMY\\nKids! Come here! INT. SOPRANO HOUSE - KITCHEN - DAY\\nTOMMY (V.O.) Hey, kids!\\nThe teenagers trudge dutifully to the door. EXT. SOPRANO BACKYARD - POOL - DAY TOMMY\\nLook! They're trying to fly. KIDS\\n(bored, humoring) Nice, dad. National Geographic. [ETC] They go back inside. INT. SOPRANO HOUSE - KITCHEN - DAY HUNTER\\nIt is so cool you're going to be able to come to Aspen with my family at Christmas. Last year at Aspen? I saw Skeet Ulrich. As close as from where you're sitting. MEADOW\\nOmigod. INT. DR. MELFI'S OFFICE - DAY TOMMY\\nMy wife feels this friend of Meadow's is a bad influence. INT. SOPRANO HOUSE - KITCHEN - DAY CARMELA\\nMiss Meadow, we made a deal — you keep your school grades up and you keep your curfew between now and Christmas — then you get to go. MEADOW\\n(edge) I know that. Tommy enters, robe gone, his lower torso wrapped in a beach towel. He claps Tommy Jr. on the back. TOMMY\\nHappy birthday, son. He runs his hand on Carmela's butt, but she seems not to notice. So he starts slap fighting with Tommy Jr. CARMELA\\nYou're going to be home tonight for Tommy Jr.'s party, right? (to his grunt) Birdman. Hello? TOMMY\\nI'll get home from work early. CARMELA\\nI wasn't talking about work. She moves off sullenly. As he watches her — INT. DR. MELFI'S OFFICE - DAY\\nTommy — in the present — a strained silence. She stares. TOMMY\\nThis isn't going to work. I can't talk about my personal life. MELFI\\nIt's hard for everybody. TOMMY\\nYou don't understand. MELFI\\nFinish telling me about the day you collapsed. INT. CHRIS' CAR - DAY\\nBack to the past. Brand new Lexus 400. TOMMY (V.O.)\\nI rode to work with my nephew, Christopher...he's learning the business. CHRIS MOLTISANTI (25) is in cool-ass cruise mode. Good looking — almost pretty — wears an earring, a Jersey Shark's ball cap. He is chuckling at Howard Stern on the radio. Tommy rides passenger, engrossed in his Audubon book. TOMMY (V.O.)\\nHe's an example of what I was saying before... TOMMY\\nYou call whatsisname at Triboro Towers about the hauling contract? CHRIS\\nI got home too late last night. I didn't want to wake the man up. TOMMY\\nYou get up early this morning and call? He's always in the office at six. CHRIS\\nI was nauseous this morning. My mom told me I shouldn't even go in today. TOMMY (V.O.)\\nBear in mind, this is a kid who just bought himself a 60,000 dollar Lexus. They are now in a business district. Chris' head whips around. EXT. STREET - BUSINESS DISTRICT - US/HMO - DAY CHRIS\\nIt's that guy. Mahaffey. TOMMY\\nGet out. CHRIS\\nBack there. See? With the boo-boo in red? TOMMY\\nBack up. ON MAHAFFEY a forty-four-year-old executive, walking with a YOUNG WOMAN, a secretary. They carry lattes and bagels.\\nThe Lexus pulls up. Tommy gets out — INT. DR. MELFI'S OFFICE - DAY TOMMY\\nThere was an issue of an outstanding loan — MELFI\\nLet me stop you a second. TOMMY\\nSure. MELFI\\nI have no idea where this story is going...but there are a few ethical ground rules we should quickly get out of the way. He waits. She smiles nervously. MELFI\\nYou said you were in waste management... TOMMY\\nRecycle. The environment. MELFI\\nDr. Cusamano, besides being your family physician, is also your next door neighbor. See what I'm saying? TOMMY\\nI get it. Yeah. MELFI\\n(dry mouth) What you tell me in here falls under doctor/patient confidentiality. Except — if I was, for example, to hear that a...say a...murder? was about to take place — (quickly) not that I'm saying — but, if.. Well, anything like that...where a patient tells me someone is going to be hurt? I'm supposed to go to the authorities. Technically. TOMMY\\n(long beat) Oh. MELFI\\nI don't know what happened with this Mahaffey fellow. I'm just saying. TOMMY\\nI see. TOMMY\\n(beat) Nothing. We had coffee. EXT. STREET - BUSINESS DISTRICT - US/HMQ - DAY\\nWhen Mahaffey sees Tommy, his latte spatters the sidewalk as he takes off running! Chris takes after him.\\nTHE PURSUIT Chris and Mahaffey burn up the sidewalk. Bystanders peer curiously. Tommy calmly gets behind the Lexus wheel, makes a U-turn.\\nMahaffey runs toward a sleek five story office building, US/HMO. He cuts across the lawn making for the front entrance. MAHAFFEY\\nSecurity! Chris closes, grabs him by his neck, tries to swing him to the ground. Chris loses his footing on the slippery grass and Mahaffey twirls free. But Chris is now between him and the door; Mahaffey cuts for the parking lot, panting, full out, grabbing in his pocket for his car keys. Chris runs after him into the lot. EXT. PARKING LOT - DAY\\nTommy suddenly draws abreast of Chris in the Lex, gives a cheerful TOOT, then accelerates down the parking aisle. Mahaffey's legs churning.\\nTHE LEXUS deliberately clips Mahaffey. He hurtles over the car about thirty feet, crashes to the ground. Tommy calmly gets out. MAHAFFEY\\nMy leg! It's broken! Oh fuck, oh fuck, the bone's coming through! Tommy starts punching him in the face briskly and efficiently. TOMMY\\nI'll give you a fuckin' bone. Where's my money? The secretary comes up, watches in horror. One of the Lexus' headlights hangs by its wires and Chris broken-heartedly tries to put it back in. MAHAFFEY\\nI'll get the money! Tommy continues punching, but tiring. TOMMY\\nI know you'll get the — (sees Chris fussing over the car) TOMMY\\nThe fuck you doing? Get over here. Chris crosses, takes over the physical labor — kicking Mahaffey in chest and stomach while Tommy catches his breath and picks up where he left off — TOMMY\\nI know you'll get the money. What you ought to fuckin' get is a fuckin' cork to put in your mouth. \""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "body = soup.body\n",
    "bodytext = body.text\n",
    "\n",
    "\n",
    "bodytext = re.sub(r\"\\s{2,}\", \" \", bodytext)\n",
    "\n",
    "bodytext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Extracting some basic data from text\n",
    "\n",
    "In notebook 02, we created a function `get_text_data` that uses the **spaCY library** to extract some basic information from a text, including:\n",
    "\n",
    "+ number of tokens (as counted using two different methods)\n",
    "+ a list of geopolitical (GPE) entities\n",
    "+ a list of person names\n",
    "+ a filtered list of tokens (words and punctuation is \"filtered\" by removing common \"stopwords\" like \"the\", \"and\", \"this\" and \"that\", etc.)\n",
    "\n",
    "The function is also copied in a standalone python file (.py) named \"text_functions.py\". We can import the `get_text_data` function from this python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_functions import get_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2360"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The get_text_data function returns the following data: \n",
    "# * numtokens_split = number of tokens in text identified using the split() method, \n",
    "# * numtokens_spacy = number of tokens using more advanced tokenization methods from spaCY library\n",
    "# * gpelist = list of Geopolitical Entities (GPEs) in text (i.e. countries, major cities), \n",
    "# * personlist = list of people named in text, \n",
    "# * filtered_tokens = list of tokens after removing stop words (common words that do not encode meaning, i.e. \"and, the, a, this, that, there, etc.\")\n",
    "\n",
    "textdata = get_text_data(bodytext)\n",
    "textdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Aspen': 2,\n",
       "         'New Jersey': 1,\n",
       "         'Canada': 1,\n",
       "         'Carmela': 1,\n",
       "         \"Jersey Shark's\": 1,\n",
       "         'US': 1,\n",
       "         'Tommy': 1})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpes = textdata[2]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(gpes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Tommy': 15,\n",
       "         'Chris': 11,\n",
       "         'V.O.': 8,\n",
       "         'Mahaffey': 6,\n",
       "         'Soprano': 2,\n",
       "         'Cusamano': 2,\n",
       "         'Meadow': 2,\n",
       "         \"Tommy Jr.'s\": 2,\n",
       "         'SOPRANO BACKYARD - POOL - DAY': 2,\n",
       "         'CHRIS': 2,\n",
       "         'Klimpt': 1,\n",
       "         'JENNIFER MELFI': 1,\n",
       "         'SOPRANO HOUSE - BEDROOM - DAWN': 1,\n",
       "         'SOPRANO BACKYARD - DAY': 1,\n",
       "         'Tommy beams': 1,\n",
       "         'Bon Jovi': 1,\n",
       "         'Skeet Ulrich': 1,\n",
       "         'Omigod': 1,\n",
       "         'Tommy Jr.': 1,\n",
       "         'Tommy Jr. CARMELA\\n': 1,\n",
       "         'Christopher': 1,\n",
       "         'CHRIS MOLTISANTI': 1,\n",
       "         'Howard Stern': 1,\n",
       "         'TOMMY': 1})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = textdata[3]\n",
    "\n",
    "Counter(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.': 201,\n",
       "         '\\n': 95,\n",
       "         ',': 74,\n",
       "         '-': 45,\n",
       "         'TOMMY': 39,\n",
       "         '?': 33,\n",
       "         'MELFI': 24,\n",
       "         '(': 23,\n",
       "         ')': 23,\n",
       "         'Tommy': 22,\n",
       "         '—': 22,\n",
       "         'DAY': 17,\n",
       "         'SOPRANO': 13,\n",
       "         'INT': 11,\n",
       "         \"'\": 11,\n",
       "         'Chris': 11,\n",
       "         'V.O.': 10,\n",
       "         '!': 10,\n",
       "         'Mahaffey': 10,\n",
       "         '...': 9,\n",
       "         'EXT': 8,\n",
       "         'work': 7,\n",
       "         'know': 7,\n",
       "         'HOUSE': 7,\n",
       "         'CARMELA': 7,\n",
       "         'DR': 6,\n",
       "         'HUNTER': 6,\n",
       "         'CHRIS': 6,\n",
       "         'morning': 5,\n",
       "         'pool': 5,\n",
       "         'MEADOW': 5,\n",
       "         'going': 5,\n",
       "         'Lexus': 5,\n",
       "         'door': 4,\n",
       "         'OFFICE': 4,\n",
       "         'ground': 4,\n",
       "         'like': 4,\n",
       "         'ducks': 4,\n",
       "         'takes': 4,\n",
       "         'KITCHEN': 4,\n",
       "         'Meadow': 4,\n",
       "         'home': 4,\n",
       "         'Jr.': 4,\n",
       "         'saying': 4,\n",
       "         '/': 4,\n",
       "         'MAHAFFEY': 4,\n",
       "         'stares': 3,\n",
       "         'silence': 3,\n",
       "         'family': 3,\n",
       "         'collapsed': 3,\n",
       "         'panic': 3,\n",
       "         'attack': 3,\n",
       "         'feeling': 3,\n",
       "         'lawn': 3,\n",
       "         'night': 3,\n",
       "         'BACKYARD': 3,\n",
       "         'friend': 3,\n",
       "         'school': 3,\n",
       "         'food': 3,\n",
       "         'starts': 3,\n",
       "         'mouth': 3,\n",
       "         'pastry': 3,\n",
       "         'Oh': 3,\n",
       "         ';': 3,\n",
       "         'runs': 3,\n",
       "         'gets': 3,\n",
       "         'car': 3,\n",
       "         'fuck': 3,\n",
       "         'fuckin': 3,\n",
       "         'money': 3,\n",
       "         'sits': 2,\n",
       "         'waits': 2,\n",
       "         'Soprano': 2,\n",
       "         'looks': 2,\n",
       "         'physician': 2,\n",
       "         'Dr.': 2,\n",
       "         'Cusamano': 2,\n",
       "         'said': 2,\n",
       "         'came': 2,\n",
       "         'management': 2,\n",
       "         'face': 2,\n",
       "         'Look': 2,\n",
       "         'talk': 2,\n",
       "         'DAWN': 2,\n",
       "         'Jersey': 2,\n",
       "         'thing': 2,\n",
       "         'lamps': 2,\n",
       "         'day': 2,\n",
       "         'got': 2,\n",
       "         ':': 2,\n",
       "         'late': 2,\n",
       "         'driveway': 2,\n",
       "         'goes': 2,\n",
       "         'father': 2,\n",
       "         'better': 2,\n",
       "         'water': 2,\n",
       "         'wild': 2,\n",
       "         'mother': 2,\n",
       "         'comes': 2,\n",
       "         'Yum': 2,\n",
       "         'makes': 2,\n",
       "         'kids': 2,\n",
       "         'dark': 2,\n",
       "         'pretty': 2,\n",
       "         'lites': 2,\n",
       "         'daughter': 2,\n",
       "         'brain': 2,\n",
       "         'enters': 2,\n",
       "         'cereal': 2,\n",
       "         'Carmela': 2,\n",
       "         'crosses': 2,\n",
       "         'want': 2,\n",
       "         'Italian': 2,\n",
       "         'Hello': 2,\n",
       "         'hand': 2,\n",
       "         'POOL': 2,\n",
       "         'ramp': 2,\n",
       "         'robe': 2,\n",
       "         'suddenly': 2,\n",
       "         'cool': 2,\n",
       "         'Aspen': 2,\n",
       "         'Christmas': 2,\n",
       "         'year': 2,\n",
       "         'early': 2,\n",
       "         'watches': 2,\n",
       "         'business': 2,\n",
       "         'example': 2,\n",
       "         'office': 2,\n",
       "         'STREET': 2,\n",
       "         'BUSINESS': 2,\n",
       "         'DISTRICT': 2,\n",
       "         'HMO': 2,\n",
       "         'boo': 2,\n",
       "         'secretary': 2,\n",
       "         'story': 2,\n",
       "         'quickly': 2,\n",
       "         'patient': 2,\n",
       "         'beat': 2,\n",
       "         'sees': 2,\n",
       "         'sidewalk': 2,\n",
       "         'calmly': 2,\n",
       "         'cuts': 2,\n",
       "         'tries': 2,\n",
       "         'parking': 2,\n",
       "         'lot': 2,\n",
       "         'broken': 2,\n",
       "         'bone': 2,\n",
       "         'punching': 2,\n",
       "         ' ': 1,\n",
       "         'WAITING': 1,\n",
       "         'ROOM': 1,\n",
       "         'THOMAS': 1,\n",
       "         '40': 1,\n",
       "         'Uneasily': 1,\n",
       "         'Staring': 1,\n",
       "         'confusedly': 1,\n",
       "         'vaguely': 1,\n",
       "         'erotic': 1,\n",
       "         'Klimpt': 1,\n",
       "         'reproduction': 1,\n",
       "         'Inner': 1,\n",
       "         'opens': 1,\n",
       "         'JENNIFER': 1,\n",
       "         'attractive': 1,\n",
       "         '35': 1,\n",
       "         'appears': 1,\n",
       "         'Mr.': 1,\n",
       "         'Melfi': 1,\n",
       "         'gestures': 1,\n",
       "         'choice': 1,\n",
       "         'seating': 1,\n",
       "         'seat': 1,\n",
       "         'seats': 1,\n",
       "         'facing': 1,\n",
       "         'armchair': 1,\n",
       "         'polite': 1,\n",
       "         'expectant': 1,\n",
       "         'gaze': 1,\n",
       "         'waiting': 1,\n",
       "         'utter': 1,\n",
       "         'happens': 1,\n",
       "         'psychotherapy': 1,\n",
       "         'Finally': 1,\n",
       "         'understanding': 1,\n",
       "         'unable': 1,\n",
       "         'breathe': 1,\n",
       "         'Possibly': 1,\n",
       "         'neurological': 1,\n",
       "         'blood': 1,\n",
       "         'negative': 1,\n",
       "         'sent': 1,\n",
       "         'agree': 1,\n",
       "         'laughs': 1,\n",
       "         'loud': 1,\n",
       "         'Fine': 1,\n",
       "         'line': 1,\n",
       "         'Waste': 1,\n",
       "         'consultant': 1,\n",
       "         'keeps': 1,\n",
       "         'psychiatric': 1,\n",
       "         'poker': 1,\n",
       "         'reaction': 1,\n",
       "         'impossible': 1,\n",
       "         'psychiatrist': 1,\n",
       "         'thoughts': 1,\n",
       "         'blacked': 1,\n",
       "         'shrugs': 1,\n",
       "         'Fidgets': 1,\n",
       "         'Stress/': 1,\n",
       "         'maybe': 1,\n",
       "         'Stress': 1,\n",
       "         'split': 1,\n",
       "         'level': 1,\n",
       "         'New': 1,\n",
       "         'distinguishing': 1,\n",
       "         'neighbors': 1,\n",
       "         'high': 1,\n",
       "         'security': 1,\n",
       "         'fencing': 1,\n",
       "         'mercury': 1,\n",
       "         'vapor': 1,\n",
       "         'bright': 1,\n",
       "         'baseball': 1,\n",
       "         'sensor': 1,\n",
       "         'reels': 1,\n",
       "         'dawn': 1,\n",
       "         'rays': 1,\n",
       "         'switch': 1,\n",
       "         'BEDROOM': 1,\n",
       "         'EYE': 1,\n",
       "         'slams': 1,\n",
       "         'open': 1,\n",
       "         'sleep': 1,\n",
       "         'soberly': 1,\n",
       "         'ceiling': 1,\n",
       "         'sick': 1,\n",
       "         'thinking': 1,\n",
       "         'good': 1,\n",
       "         'floor': 1,\n",
       "         'lately': 1,\n",
       "         'getting': 1,\n",
       "         'end': 1,\n",
       "         'best': 1,\n",
       "         'Bathrobed': 1,\n",
       "         'reads': 1,\n",
       "         'paper': 1,\n",
       "         'gated': 1,\n",
       "         'CLINTON': 1,\n",
       "         'WARNS': 1,\n",
       "         'MEDICARE': 1,\n",
       "         'BANKRUPT': 1,\n",
       "         'YEAR': 1,\n",
       "         '2000': 1,\n",
       "         'Sports': 1,\n",
       "         'ambles': 1,\n",
       "         'Americans': 1,\n",
       "         'think': 1,\n",
       "         'feel': 1,\n",
       "         'reached': 1,\n",
       "         'heights': 1,\n",
       "         'ways': 1,\n",
       "         'people': 1,\n",
       "         'standards': 1,\n",
       "         'pride': 1,\n",
       "         'Today': 1,\n",
       "         '.got': 1,\n",
       "         'loss': 1,\n",
       "         'acutely': 1,\n",
       "         'hours': 1,\n",
       "         'expanse': 1,\n",
       "         'Tropitone': 1,\n",
       "         'furniture': 1,\n",
       "         'gathers': 1,\n",
       "         'speed': 1,\n",
       "         'excited': 1,\n",
       "         'reaching': 1,\n",
       "         'worried': 1,\n",
       "         'glass': 1,\n",
       "         'dunno': 1,\n",
       "         'Couple': 1,\n",
       "         'months': 1,\n",
       "         'landed': 1,\n",
       "         'Amazing': 1,\n",
       "         'Canada': 1,\n",
       "         'someplace': 1,\n",
       "         'mating': 1,\n",
       "         'season': 1,\n",
       "         'DUCK': 1,\n",
       "         'FAMILY': 1,\n",
       "         'mallards': 1,\n",
       "         'babies': 1,\n",
       "         'waddling': 1,\n",
       "         'bushes': 1,\n",
       "         'QUACKING': 1,\n",
       "         'beams': 1,\n",
       "         'feed': 1,\n",
       "         'bin': 1,\n",
       "         'drops': 1,\n",
       "         'knees': 1,\n",
       "         'feeds': 1,\n",
       "         'mid': 1,\n",
       "         '30': 1,\n",
       "         'bathrobe': 1,\n",
       "         'breakfast': 1,\n",
       "         'eyed': 1,\n",
       "         'haired': 1,\n",
       "         'woman': 1,\n",
       "         'blonde': 1,\n",
       "         'hi': 1,\n",
       "         'Hi': 1,\n",
       "         'nails': 1,\n",
       "         'priority': 1,\n",
       "         'table': 1,\n",
       "         '15': 1,\n",
       "         'SCANGARELO': 1,\n",
       "         'drive': 1,\n",
       "         'staring': 1,\n",
       "         'window': 1,\n",
       "         'cran-': 1,\n",
       "         'apple': 1,\n",
       "         'juice': 1,\n",
       "         'ladies': 1,\n",
       "         'need': 1,\n",
       "         'JR': 1,\n",
       "         'thirteen': 1,\n",
       "         'spooning': 1,\n",
       "         'smooches': 1,\n",
       "         'ad': 1,\n",
       "         'libs': 1,\n",
       "         'happy': 1,\n",
       "         'birthdays': 1,\n",
       "         'acknowledges': 1,\n",
       "         'crammed': 1,\n",
       "         'male': 1,\n",
       "         'female': 1,\n",
       "         'duck': 1,\n",
       "         'Weird': 1,\n",
       "         'Girls': 1,\n",
       "         'sfogliatell': 1,\n",
       "         'fat': 1,\n",
       "         'bite': 1,\n",
       "         'Wait': 1,\n",
       "         'Bon': 1,\n",
       "         'Jovi': 1,\n",
       "         'laugh': 1,\n",
       "         'box': 1,\n",
       "         'dunks': 1,\n",
       "         'milk': 1,\n",
       "         'eats': 1,\n",
       "         'girls': 1,\n",
       "         'ee': 1,\n",
       "         'ew': 1,\n",
       "         'stay': 1,\n",
       "         'skinny': 1,\n",
       "         'Mrs.': 1,\n",
       "         'waded': 1,\n",
       "         'adjust': 1,\n",
       "         'plywood': 1,\n",
       "         'launching': 1,\n",
       "         'constructed': 1,\n",
       "         'floats': 1,\n",
       "         'care': 1,\n",
       "         'talks': 1,\n",
       "         'worry': 1,\n",
       "         'ducklings': 1,\n",
       "         'furiously': 1,\n",
       "         'flap': 1,\n",
       "         'wings': 1,\n",
       "         'protoflight': 1,\n",
       "         'following': 1,\n",
       "         'lead': 1,\n",
       "         'Kids': 1,\n",
       "         'Come': 1,\n",
       "         'Hey': 1,\n",
       "         'teenagers': 1,\n",
       "         'trudge': 1,\n",
       "         'dutifully': 1,\n",
       "         'trying': 1,\n",
       "         'fly': 1,\n",
       "         'KIDS': 1,\n",
       "         'bored': 1,\n",
       "         'humoring': 1,\n",
       "         'Nice': 1,\n",
       "         'dad': 1,\n",
       "         'National': 1,\n",
       "         'Geographic': 1,\n",
       "         '[': 1,\n",
       "         'ETC': 1,\n",
       "         ']': 1,\n",
       "         'inside': 1,\n",
       "         'able': 1,\n",
       "         'come': 1,\n",
       "         'saw': 1,\n",
       "         'Skeet': 1,\n",
       "         'Ulrich': 1,\n",
       "         'close': 1,\n",
       "         'sitting': 1,\n",
       "         'Omigod': 1,\n",
       "         'wife': 1,\n",
       "         'feels': 1,\n",
       "         'bad': 1,\n",
       "         'influence': 1,\n",
       "         'Miss': 1,\n",
       "         'deal': 1,\n",
       "         'grades': 1,\n",
       "         'curfew': 1,\n",
       "         'edge': 1,\n",
       "         'gone': 1,\n",
       "         'lower': 1,\n",
       "         'torso': 1,\n",
       "         'wrapped': 1,\n",
       "         'beach': 1,\n",
       "         'towel': 1,\n",
       "         'claps': 1,\n",
       "         'Happy': 1,\n",
       "         'birthday': 1,\n",
       "         'son': 1,\n",
       "         'butt': 1,\n",
       "         'notice': 1,\n",
       "         'slap': 1,\n",
       "         'fighting': 1,\n",
       "         'tonight': 1,\n",
       "         'party': 1,\n",
       "         'right': 1,\n",
       "         'grunt': 1,\n",
       "         'Birdman': 1,\n",
       "         'talking': 1,\n",
       "         'moves': 1,\n",
       "         'sullenly': 1,\n",
       "         'present': 1,\n",
       "         'strained': 1,\n",
       "         'personal': 1,\n",
       "         'life': 1,\n",
       "         'hard': 1,\n",
       "         'everybody': 1,\n",
       "         'understand': 1,\n",
       "         'Finish': 1,\n",
       "         'telling': 1,\n",
       "         'CAR': 1,\n",
       "         'past': 1,\n",
       "         'Brand': 1,\n",
       "         'new': 1,\n",
       "         '400': 1,\n",
       "         'rode': 1,\n",
       "         'nephew': 1,\n",
       "         'Christopher': 1,\n",
       "         'learning': 1,\n",
       "         'MOLTISANTI': 1,\n",
       "         '25': 1,\n",
       "         'ass': 1,\n",
       "         'cruise': 1,\n",
       "         'mode': 1,\n",
       "         'Good': 1,\n",
       "         'looking': 1,\n",
       "         'wears': 1,\n",
       "         'earring': 1,\n",
       "         'Shark': 1,\n",
       "         'ball': 1,\n",
       "         'cap': 1,\n",
       "         'chuckling': 1,\n",
       "         'Howard': 1,\n",
       "         'Stern': 1,\n",
       "         'radio': 1,\n",
       "         'rides': 1,\n",
       "         'passenger': 1,\n",
       "         'engrossed': 1,\n",
       "         'Audubon': 1,\n",
       "         'book': 1,\n",
       "         'whatsisname': 1,\n",
       "         'Triboro': 1,\n",
       "         'Towers': 1,\n",
       "         'hauling': 1,\n",
       "         'contract': 1,\n",
       "         'wake': 1,\n",
       "         'man': 1,\n",
       "         'nauseous': 1,\n",
       "         'mom': 1,\n",
       "         'told': 1,\n",
       "         'today': 1,\n",
       "         'Bear': 1,\n",
       "         'mind': 1,\n",
       "         'kid': 1,\n",
       "         'bought': 1,\n",
       "         '60,000': 1,\n",
       "         'dollar': 1,\n",
       "         'district': 1,\n",
       "         'head': 1,\n",
       "         'whips': 1,\n",
       "         'guy': 1,\n",
       "         'red': 1,\n",
       "         'old': 1,\n",
       "         'executive': 1,\n",
       "         'walking': 1,\n",
       "         'YOUNG': 1,\n",
       "         'WOMAN': 1,\n",
       "         'carry': 1,\n",
       "         'lattes': 1,\n",
       "         'bagels': 1,\n",
       "         'pulls': 1,\n",
       "         'issue': 1,\n",
       "         'outstanding': 1,\n",
       "         'loan': 1,\n",
       "         'Let': 1,\n",
       "         'stop': 1,\n",
       "         'second': 1,\n",
       "         'Sure': 1,\n",
       "         'idea': 1,\n",
       "         'ethical': 1,\n",
       "         'rules': 1,\n",
       "         'way': 1,\n",
       "         'smiles': 1,\n",
       "         'nervously': 1,\n",
       "         'waste': 1,\n",
       "         'Recycle': 1,\n",
       "         'environment': 1,\n",
       "         'neighbor': 1,\n",
       "         'Yeah': 1,\n",
       "         'dry': 1,\n",
       "         'tell': 1,\n",
       "         'falls': 1,\n",
       "         'doctor': 1,\n",
       "         'confidentiality': 1,\n",
       "         'hear': 1,\n",
       "         'murder': 1,\n",
       "         'place': 1,\n",
       "         '..': 1,\n",
       "         'tells': 1,\n",
       "         'hurt': 1,\n",
       "         'supposed': 1,\n",
       "         'authorities': 1,\n",
       "         'Technically': 1,\n",
       "         'long': 1,\n",
       "         'happened': 1,\n",
       "         'fellow': 1,\n",
       "         'coffee': 1,\n",
       "         'HMQ': 1,\n",
       "         'latte': 1,\n",
       "         'spatters': 1,\n",
       "         'running': 1,\n",
       "         'PURSUIT': 1,\n",
       "         'burn': 1,\n",
       "         'Bystanders': 1,\n",
       "         'peer': 1,\n",
       "         'curiously': 1,\n",
       "         'wheel': 1,\n",
       "         'U': 1,\n",
       "         'turn': 1,\n",
       "         'sleek': 1,\n",
       "         'building': 1,\n",
       "         'making': 1,\n",
       "         'entrance': 1,\n",
       "         'Security': 1,\n",
       "         'closes': 1,\n",
       "         'grabs': 1,\n",
       "         'neck': 1,\n",
       "         'swing': 1,\n",
       "         'loses': 1,\n",
       "         'footing': 1,\n",
       "         'slippery': 1,\n",
       "         'grass': 1,\n",
       "         'twirls': 1,\n",
       "         'free': 1,\n",
       "         'panting': 1,\n",
       "         'grabbing': 1,\n",
       "         'pocket': 1,\n",
       "         'keys': 1,\n",
       "         'PARKING': 1,\n",
       "         'LOT': 1,\n",
       "         'draws': 1,\n",
       "         'abreast': 1,\n",
       "         'Lex': 1,\n",
       "         'gives': 1,\n",
       "         'cheerful': 1,\n",
       "         'TOOT': 1,\n",
       "         'accelerates': 1,\n",
       "         'aisle': 1,\n",
       "         'legs': 1,\n",
       "         'churning': 1,\n",
       "         'LEXUS': 1,\n",
       "         'deliberately': 1,\n",
       "         'clips': 1,\n",
       "         'hurtles': 1,\n",
       "         'thirty': 1,\n",
       "         'feet': 1,\n",
       "         'crashes': 1,\n",
       "         'leg': 1,\n",
       "         'oh': 1,\n",
       "         'coming': 1,\n",
       "         'briskly': 1,\n",
       "         'efficiently': 1,\n",
       "         'horror': 1,\n",
       "         'headlights': 1,\n",
       "         'hangs': 1,\n",
       "         'wires': 1,\n",
       "         'heartedly': 1,\n",
       "         'continues': 1,\n",
       "         'tiring': 1,\n",
       "         'fussing': 1,\n",
       "         'physical': 1,\n",
       "         'labor': 1,\n",
       "         'kicking': 1,\n",
       "         'chest': 1,\n",
       "         'stomach': 1,\n",
       "         'catches': 1,\n",
       "         'breath': 1,\n",
       "         'picks': 1,\n",
       "         'left': 1,\n",
       "         'ought': 1,\n",
       "         'cork': 1})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_toks = textdata[4]\n",
    "Counter(filt_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Other Preprocessing: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.': 201,\n",
       "         '\\n': 95,\n",
       "         ',': 74,\n",
       "         'the': 72,\n",
       "         'be': 67,\n",
       "         '-': 45,\n",
       "         'I': 44,\n",
       "         'a': 41,\n",
       "         'TOMMY': 38,\n",
       "         'he': 36,\n",
       "         'to': 34,\n",
       "         '?': 33,\n",
       "         'in': 32,\n",
       "         'you': 32,\n",
       "         'MELFI': 24,\n",
       "         'and': 23,\n",
       "         '(': 23,\n",
       "         ')': 23,\n",
       "         '—': 22,\n",
       "         'Tommy': 20,\n",
       "         'get': 18,\n",
       "         \"'s\": 17,\n",
       "         'DAY': 16,\n",
       "         'have': 15,\n",
       "         'his': 15,\n",
       "         'not': 14,\n",
       "         'of': 13,\n",
       "         'with': 13,\n",
       "         'it': 13,\n",
       "         'do': 13,\n",
       "         'SOPRANO': 12,\n",
       "         'at': 12,\n",
       "         'my': 12,\n",
       "         'for': 12,\n",
       "         'INT': 11,\n",
       "         'that': 11,\n",
       "         'go': 11,\n",
       "         \"'\": 11,\n",
       "         'Chris': 11,\n",
       "         'they': 10,\n",
       "         'V.O.': 10,\n",
       "         'this': 10,\n",
       "         '!': 10,\n",
       "         'Mahaffey': 10,\n",
       "         'she': 9,\n",
       "         'back': 9,\n",
       "         'from': 9,\n",
       "         '...': 9,\n",
       "         'up': 9,\n",
       "         'your': 8,\n",
       "         'what': 8,\n",
       "         'on': 8,\n",
       "         'out': 8,\n",
       "         'EXT': 8,\n",
       "         'but': 8,\n",
       "         'say': 7,\n",
       "         'work': 7,\n",
       "         'come': 7,\n",
       "         'know': 7,\n",
       "         'about': 7,\n",
       "         'HOUSE': 7,\n",
       "         'DR': 6,\n",
       "         'there': 6,\n",
       "         'make': 6,\n",
       "         'take': 6,\n",
       "         'CARMELA': 6,\n",
       "         'will': 6,\n",
       "         'see': 6,\n",
       "         'CHRIS': 6,\n",
       "         'stare': 5,\n",
       "         'here': 5,\n",
       "         'now': 5,\n",
       "         'morning': 5,\n",
       "         'over': 5,\n",
       "         'an': 5,\n",
       "         'pool': 5,\n",
       "         'duck': 5,\n",
       "         'MEADOW': 5,\n",
       "         'where': 5,\n",
       "         'Lexus': 5,\n",
       "         'wait': 4,\n",
       "         'door': 4,\n",
       "         'OFFICE': 4,\n",
       "         'too': 4,\n",
       "         'talk': 4,\n",
       "         'then': 4,\n",
       "         'off': 4,\n",
       "         'ground': 4,\n",
       "         'like': 4,\n",
       "         'we': 4,\n",
       "         'KITCHEN': 4,\n",
       "         'kid': 4,\n",
       "         'Meadow': 4,\n",
       "         'just': 4,\n",
       "         'hunter': 4,\n",
       "         'home': 4,\n",
       "         'oh': 4,\n",
       "         'Jr.': 4,\n",
       "         'as': 4,\n",
       "         'run': 4,\n",
       "         'tell': 4,\n",
       "         '/': 4,\n",
       "         'MAHAFFEY': 4,\n",
       "         'sit': 3,\n",
       "         'look': 3,\n",
       "         'silence': 3,\n",
       "         'family': 3,\n",
       "         'collapse': 3,\n",
       "         'panic': 3,\n",
       "         'attack': 3,\n",
       "         'all': 3,\n",
       "         'feel': 3,\n",
       "         'keep': 3,\n",
       "         'after': 3,\n",
       "         'tommy': 3,\n",
       "         'lawn': 3,\n",
       "         'night': 3,\n",
       "         'day': 3,\n",
       "         'good': 3,\n",
       "         'by': 3,\n",
       "         'down': 3,\n",
       "         'well': 3,\n",
       "         'their': 3,\n",
       "         'before': 3,\n",
       "         'BACKYARD': 3,\n",
       "         'friend': 3,\n",
       "         'school': 3,\n",
       "         'food': 3,\n",
       "         'start': 3,\n",
       "         'mouth': 3,\n",
       "         'pastry': 3,\n",
       "         'last': 3,\n",
       "         ';': 3,\n",
       "         'so': 3,\n",
       "         'try': 3,\n",
       "         'US': 3,\n",
       "         'parking': 3,\n",
       "         'car': 3,\n",
       "         'fuck': 3,\n",
       "         'fuckin': 3,\n",
       "         'money': 3,\n",
       "         'open': 2,\n",
       "         'Soprano': 2,\n",
       "         'seat': 2,\n",
       "         'nothing': 2,\n",
       "         'happen': 2,\n",
       "         'physician': 2,\n",
       "         'Dr.': 2,\n",
       "         'Cusamano': 2,\n",
       "         'laugh': 2,\n",
       "         'how': 2,\n",
       "         'management': 2,\n",
       "         'face': 2,\n",
       "         'DAWN': 2,\n",
       "         'Jersey': 2,\n",
       "         'thing': 2,\n",
       "         'its': 2,\n",
       "         'neighbor': 2,\n",
       "         'lamp': 2,\n",
       "         'think': 2,\n",
       "         ':': 2,\n",
       "         'late': 2,\n",
       "         'feeling': 2,\n",
       "         'driveway': 2,\n",
       "         'father': 2,\n",
       "         'reach': 2,\n",
       "         'way': 2,\n",
       "         'today': 2,\n",
       "         'more': 2,\n",
       "         'around': 2,\n",
       "         'water': 2,\n",
       "         'wild': 2,\n",
       "         'mother': 2,\n",
       "         'feed': 2,\n",
       "         'Yum': 2,\n",
       "         'her': 2,\n",
       "         'dark': 2,\n",
       "         'pretty': 2,\n",
       "         'woman': 2,\n",
       "         'lite': 2,\n",
       "         'HUNTER': 2,\n",
       "         'daughter': 2,\n",
       "         'brain': 2,\n",
       "         'enter': 2,\n",
       "         'cereal': 2,\n",
       "         'Carmela': 2,\n",
       "         'happy': 2,\n",
       "         'birthday': 2,\n",
       "         'crosse': 2,\n",
       "         'girl': 2,\n",
       "         'want': 2,\n",
       "         'italian': 2,\n",
       "         'hello': 2,\n",
       "         'hand': 2,\n",
       "         'POOL': 2,\n",
       "         'into': 2,\n",
       "         'ramp': 2,\n",
       "         'robe': 2,\n",
       "         'suddenly': 2,\n",
       "         'cool': 2,\n",
       "         'Christmas': 2,\n",
       "         'year': 2,\n",
       "         'close': 2,\n",
       "         'between': 2,\n",
       "         'early': 2,\n",
       "         'watch': 2,\n",
       "         'ride': 2,\n",
       "         'business': 2,\n",
       "         'example': 2,\n",
       "         'call': 2,\n",
       "         'office': 2,\n",
       "         'should': 2,\n",
       "         'STREET': 2,\n",
       "         'BUSINESS': 2,\n",
       "         'DISTRICT': 2,\n",
       "         'HMO': 2,\n",
       "         'boo': 2,\n",
       "         'secretary': 2,\n",
       "         'latte': 2,\n",
       "         'story': 2,\n",
       "         'quickly': 2,\n",
       "         'patient': 2,\n",
       "         'if': 2,\n",
       "         'beat': 2,\n",
       "         'sidewalk': 2,\n",
       "         'calmly': 2,\n",
       "         'cut': 2,\n",
       "         'grab': 2,\n",
       "         'lot': 2,\n",
       "         'give': 2,\n",
       "         'leg': 2,\n",
       "         'break': 2,\n",
       "         'bone': 2,\n",
       "         'punch': 2,\n",
       "         'put': 2,\n",
       "         ' ': 1,\n",
       "         'waiting': 1,\n",
       "         'ROOM': 1,\n",
       "         'THOMAS': 1,\n",
       "         '40': 1,\n",
       "         'uneasily': 1,\n",
       "         'confusedly': 1,\n",
       "         'vaguely': 1,\n",
       "         'erotic': 1,\n",
       "         'Klimpt': 1,\n",
       "         'reproduction': 1,\n",
       "         'inner': 1,\n",
       "         'JENNIFER': 1,\n",
       "         'attractive': 1,\n",
       "         '35': 1,\n",
       "         'appear': 1,\n",
       "         'Mr.': 1,\n",
       "         'Melfi': 1,\n",
       "         'gesture': 1,\n",
       "         'choice': 1,\n",
       "         'seating': 1,\n",
       "         'herself': 1,\n",
       "         'facing': 1,\n",
       "         'armchair': 1,\n",
       "         'polite': 1,\n",
       "         'expectant': 1,\n",
       "         'gaze': 1,\n",
       "         'utter': 1,\n",
       "         'such': 1,\n",
       "         'psychotherapy': 1,\n",
       "         'finally': 1,\n",
       "         'understanding': 1,\n",
       "         'unable': 1,\n",
       "         'breathe': 1,\n",
       "         'possibly': 1,\n",
       "         'because': 1,\n",
       "         'neurological': 1,\n",
       "         'blood': 1,\n",
       "         'negative': 1,\n",
       "         'send': 1,\n",
       "         'agree': 1,\n",
       "         'loud': 1,\n",
       "         'fine': 1,\n",
       "         'line': 1,\n",
       "         'Waste': 1,\n",
       "         'consultant': 1,\n",
       "         'psychiatric': 1,\n",
       "         'poker': 1,\n",
       "         'yet': 1,\n",
       "         'reaction': 1,\n",
       "         'impossible': 1,\n",
       "         'psychiatrist': 1,\n",
       "         'any': 1,\n",
       "         'thought': 1,\n",
       "         'why': 1,\n",
       "         'black': 1,\n",
       "         'shrug': 1,\n",
       "         'fidget': 1,\n",
       "         'stress/': 1,\n",
       "         'maybe': 1,\n",
       "         'stress': 1,\n",
       "         'split': 1,\n",
       "         'level': 1,\n",
       "         'New': 1,\n",
       "         'only': 1,\n",
       "         'distinguish': 1,\n",
       "         'high': 1,\n",
       "         'security': 1,\n",
       "         'fencing': 1,\n",
       "         'mercury': 1,\n",
       "         'vapor': 1,\n",
       "         'bright': 1,\n",
       "         'enough': 1,\n",
       "         'baseball': 1,\n",
       "         'sensor': 1,\n",
       "         'reel': 1,\n",
       "         'dawn': 1,\n",
       "         'ray': 1,\n",
       "         'switch': 1,\n",
       "         'BEDROOM': 1,\n",
       "         'EYE': 1,\n",
       "         'slam': 1,\n",
       "         'sleep': 1,\n",
       "         'soberly': 1,\n",
       "         'ceiling': 1,\n",
       "         'sick': 1,\n",
       "         'floor': 1,\n",
       "         'lately': 1,\n",
       "         'might': 1,\n",
       "         'end': 1,\n",
       "         'Bathrobed': 1,\n",
       "         'read': 1,\n",
       "         'paper': 1,\n",
       "         'gate': 1,\n",
       "         'CLINTON': 1,\n",
       "         'WARNS': 1,\n",
       "         'MEDICARE': 1,\n",
       "         'could': 1,\n",
       "         'bankrupt': 1,\n",
       "         'YEAR': 1,\n",
       "         '2000': 1,\n",
       "         'Sports': 1,\n",
       "         'amble': 1,\n",
       "         'many': 1,\n",
       "         'Americans': 1,\n",
       "         'never': 1,\n",
       "         'height': 1,\n",
       "         'people': 1,\n",
       "         'standard': 1,\n",
       "         'pride': 1,\n",
       "         '.got': 1,\n",
       "         'loss': 1,\n",
       "         'acutely': 1,\n",
       "         'hour': 1,\n",
       "         'expanse': 1,\n",
       "         'Tropitone': 1,\n",
       "         'furniture': 1,\n",
       "         'gather': 1,\n",
       "         'speed': 1,\n",
       "         'excited': 1,\n",
       "         'worried': 1,\n",
       "         'glass': 1,\n",
       "         'still': 1,\n",
       "         'dunno': 1,\n",
       "         'couple': 1,\n",
       "         'month': 1,\n",
       "         'these': 1,\n",
       "         'two': 1,\n",
       "         'land': 1,\n",
       "         'amazing': 1,\n",
       "         'Canada': 1,\n",
       "         'or': 1,\n",
       "         'someplace': 1,\n",
       "         'mate': 1,\n",
       "         'season': 1,\n",
       "         'DUCK': 1,\n",
       "         'FAMILY': 1,\n",
       "         'mallard': 1,\n",
       "         'baby': 1,\n",
       "         'waddle': 1,\n",
       "         'bush': 1,\n",
       "         'QUACKING': 1,\n",
       "         'beam': 1,\n",
       "         'bin': 1,\n",
       "         'drop': 1,\n",
       "         'both': 1,\n",
       "         'knee': 1,\n",
       "         'carmela': 1,\n",
       "         'soprano': 1,\n",
       "         'mid': 1,\n",
       "         '30': 1,\n",
       "         'bathrobe': 1,\n",
       "         'breakfast': 1,\n",
       "         'eye': 1,\n",
       "         'haired': 1,\n",
       "         'blonde': 1,\n",
       "         'hi': 1,\n",
       "         'Hi': 1,\n",
       "         'nail': 1,\n",
       "         'priority': 1,\n",
       "         'table': 1,\n",
       "         '15': 1,\n",
       "         'SCANGARELO': 1,\n",
       "         'drive': 1,\n",
       "         'window': 1,\n",
       "         'those': 1,\n",
       "         'something': 1,\n",
       "         'than': 1,\n",
       "         'cran-': 1,\n",
       "         'apple': 1,\n",
       "         'juice': 1,\n",
       "         'lady': 1,\n",
       "         'need': 1,\n",
       "         'JR': 1,\n",
       "         'thirteen': 1,\n",
       "         'spoon': 1,\n",
       "         'smooch': 1,\n",
       "         'everyone': 1,\n",
       "         'ad': 1,\n",
       "         'lib': 1,\n",
       "         'acknowledge': 1,\n",
       "         'cram': 1,\n",
       "         'male': 1,\n",
       "         'female': 1,\n",
       "         'weird': 1,\n",
       "         'some': 1,\n",
       "         'sfogliatell': 1,\n",
       "         'fat': 1,\n",
       "         'bite': 1,\n",
       "         'Bon': 1,\n",
       "         'Jovi': 1,\n",
       "         'box': 1,\n",
       "         'dunk': 1,\n",
       "         'milk': 1,\n",
       "         'eat': 1,\n",
       "         'ee': 1,\n",
       "         'ew': 1,\n",
       "         'stay': 1,\n",
       "         'skinny': 1,\n",
       "         'Mrs.': 1,\n",
       "         'wade': 1,\n",
       "         'adjust': 1,\n",
       "         'plywood': 1,\n",
       "         'launching': 1,\n",
       "         'construct': 1,\n",
       "         'float': 1,\n",
       "         'care': 1,\n",
       "         'worry': 1,\n",
       "         'duckling': 1,\n",
       "         'furiously': 1,\n",
       "         'flap': 1,\n",
       "         'wing': 1,\n",
       "         'protoflight': 1,\n",
       "         'follow': 1,\n",
       "         'lead': 1,\n",
       "         'Hey': 1,\n",
       "         'teenager': 1,\n",
       "         'trudge': 1,\n",
       "         'dutifully': 1,\n",
       "         'Look': 1,\n",
       "         'fly': 1,\n",
       "         'KIDS': 1,\n",
       "         'bore': 1,\n",
       "         'humor': 1,\n",
       "         'Nice': 1,\n",
       "         'dad': 1,\n",
       "         'National': 1,\n",
       "         'Geographic': 1,\n",
       "         '[': 1,\n",
       "         'etc': 1,\n",
       "         ']': 1,\n",
       "         'inside': 1,\n",
       "         'able': 1,\n",
       "         'aspen': 1,\n",
       "         'Aspen': 1,\n",
       "         'Skeet': 1,\n",
       "         'Ulrich': 1,\n",
       "         'Omigod': 1,\n",
       "         'wife': 1,\n",
       "         'bad': 1,\n",
       "         'influence': 1,\n",
       "         'Miss': 1,\n",
       "         'deal': 1,\n",
       "         'grade': 1,\n",
       "         'curfew': 1,\n",
       "         'edge': 1,\n",
       "         'gone': 1,\n",
       "         'low': 1,\n",
       "         'torso': 1,\n",
       "         'wrap': 1,\n",
       "         'beach': 1,\n",
       "         'towel': 1,\n",
       "         'clap': 1,\n",
       "         'son': 1,\n",
       "         'butt': 1,\n",
       "         'seem': 1,\n",
       "         'notice': 1,\n",
       "         'slap': 1,\n",
       "         'fighting': 1,\n",
       "         'tonight': 1,\n",
       "         'party': 1,\n",
       "         'right': 1,\n",
       "         'grunt': 1,\n",
       "         'birdman': 1,\n",
       "         'move': 1,\n",
       "         'sullenly': 1,\n",
       "         'present': 1,\n",
       "         'strained': 1,\n",
       "         'can': 1,\n",
       "         'personal': 1,\n",
       "         'life': 1,\n",
       "         'hard': 1,\n",
       "         'everybody': 1,\n",
       "         'understand': 1,\n",
       "         'finish': 1,\n",
       "         'CAR': 1,\n",
       "         'past': 1,\n",
       "         'brand': 1,\n",
       "         'new': 1,\n",
       "         '400': 1,\n",
       "         'nephew': 1,\n",
       "         'Christopher': 1,\n",
       "         'learn': 1,\n",
       "         'MOLTISANTI': 1,\n",
       "         '25': 1,\n",
       "         'ass': 1,\n",
       "         'cruise': 1,\n",
       "         'mode': 1,\n",
       "         'looking': 1,\n",
       "         'almost': 1,\n",
       "         'wear': 1,\n",
       "         'earring': 1,\n",
       "         'Shark': 1,\n",
       "         'ball': 1,\n",
       "         'cap': 1,\n",
       "         'chuckle': 1,\n",
       "         'Howard': 1,\n",
       "         'Stern': 1,\n",
       "         'radio': 1,\n",
       "         'passenger': 1,\n",
       "         'engross': 1,\n",
       "         'Audubon': 1,\n",
       "         'book': 1,\n",
       "         'whatsisname': 1,\n",
       "         'Triboro': 1,\n",
       "         'Towers': 1,\n",
       "         'haul': 1,\n",
       "         'contract': 1,\n",
       "         'wake': 1,\n",
       "         'man': 1,\n",
       "         'always': 1,\n",
       "         'six': 1,\n",
       "         'nauseous': 1,\n",
       "         'mom': 1,\n",
       "         'even': 1,\n",
       "         'Bear': 1,\n",
       "         'mind': 1,\n",
       "         'who': 1,\n",
       "         'buy': 1,\n",
       "         'himself': 1,\n",
       "         '60,000': 1,\n",
       "         'dollar': 1,\n",
       "         'district': 1,\n",
       "         'head': 1,\n",
       "         'whip': 1,\n",
       "         'guy': 1,\n",
       "         'red': 1,\n",
       "         'forty': 1,\n",
       "         'four': 1,\n",
       "         'old': 1,\n",
       "         'executive': 1,\n",
       "         'walk': 1,\n",
       "         'young': 1,\n",
       "         'carry': 1,\n",
       "         'bagel': 1,\n",
       "         'pull': 1,\n",
       "         'issue': 1,\n",
       "         'outstanding': 1,\n",
       "         'loan': 1,\n",
       "         'let': 1,\n",
       "         'stop': 1,\n",
       "         'second': 1,\n",
       "         'Sure': 1,\n",
       "         'no': 1,\n",
       "         'idea': 1,\n",
       "         'few': 1,\n",
       "         'ethical': 1,\n",
       "         'rule': 1,\n",
       "         'smile': 1,\n",
       "         'nervously': 1,\n",
       "         'waste': 1,\n",
       "         'Recycle': 1,\n",
       "         'environment': 1,\n",
       "         'besides': 1,\n",
       "         'also': 1,\n",
       "         'next': 1,\n",
       "         'yeah': 1,\n",
       "         'dry': 1,\n",
       "         'fall': 1,\n",
       "         'under': 1,\n",
       "         'doctor': 1,\n",
       "         'confidentiality': 1,\n",
       "         'except': 1,\n",
       "         'hear': 1,\n",
       "         'murder': 1,\n",
       "         'place': 1,\n",
       "         '..': 1,\n",
       "         'anything': 1,\n",
       "         'someone': 1,\n",
       "         'hurt': 1,\n",
       "         'suppose': 1,\n",
       "         'authority': 1,\n",
       "         'Technically': 1,\n",
       "         'long': 1,\n",
       "         'fellow': 1,\n",
       "         'coffee': 1,\n",
       "         'HMQ': 1,\n",
       "         'when': 1,\n",
       "         'spatter': 1,\n",
       "         'PURSUIT': 1,\n",
       "         'burn': 1,\n",
       "         'bystander': 1,\n",
       "         'peer': 1,\n",
       "         'curiously': 1,\n",
       "         'behind': 1,\n",
       "         'wheel': 1,\n",
       "         'u': 1,\n",
       "         'turn': 1,\n",
       "         'toward': 1,\n",
       "         'sleek': 1,\n",
       "         'five': 1,\n",
       "         'building': 1,\n",
       "         'across': 1,\n",
       "         'making': 1,\n",
       "         'front': 1,\n",
       "         'entrance': 1,\n",
       "         'Security': 1,\n",
       "         'neck': 1,\n",
       "         'swing': 1,\n",
       "         'lose': 1,\n",
       "         'footing': 1,\n",
       "         'slippery': 1,\n",
       "         'grass': 1,\n",
       "         'twirl': 1,\n",
       "         'free': 1,\n",
       "         'pant': 1,\n",
       "         'full': 1,\n",
       "         'pocket': 1,\n",
       "         'key': 1,\n",
       "         'LOT': 1,\n",
       "         'draw': 1,\n",
       "         'abreast': 1,\n",
       "         'Lex': 1,\n",
       "         'cheerful': 1,\n",
       "         'toot': 1,\n",
       "         'accelerate': 1,\n",
       "         'aisle': 1,\n",
       "         'churn': 1,\n",
       "         'LEXUS': 1,\n",
       "         'deliberately': 1,\n",
       "         'clip': 1,\n",
       "         'hurtle': 1,\n",
       "         'thirty': 1,\n",
       "         'foot': 1,\n",
       "         'crash': 1,\n",
       "         'through': 1,\n",
       "         'briskly': 1,\n",
       "         'efficiently': 1,\n",
       "         'horror': 1,\n",
       "         'one': 1,\n",
       "         'headlight': 1,\n",
       "         'hang': 1,\n",
       "         'wire': 1,\n",
       "         'heartedly': 1,\n",
       "         'continue': 1,\n",
       "         'tiring': 1,\n",
       "         'fuss': 1,\n",
       "         'physical': 1,\n",
       "         'labor': 1,\n",
       "         'kick': 1,\n",
       "         'chest': 1,\n",
       "         'stomach': 1,\n",
       "         'while': 1,\n",
       "         'catch': 1,\n",
       "         'breath': 1,\n",
       "         'pick': 1,\n",
       "         'leave': 1,\n",
       "         'ought': 1,\n",
       "         'cork': 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(bodytext)\n",
    "\n",
    "lemmas = []\n",
    "for token in doc:\n",
    "    lemmas.append(token.lemma_)\n",
    "\n",
    "Counter(lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sp>\n",
       "<speaker>MELFI</speaker>\n",
       "<l>My understanding from your family physician, Dr. Cusamano, is you collapsed? Were unable to breathe? Possibly a panic attack?</l>\n",
       "</sp>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = body.find_all(\"sp\")\n",
    "print(len(speeches))\n",
    "speeches[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'TOMMY': 29,\n",
       "         'MELFI': 16,\n",
       "         'TOMMY (V.O.)': 7,\n",
       "         'CARMELA': 6,\n",
       "         'HUNTER': 5,\n",
       "         'MEADOW': 4,\n",
       "         'CHRIS': 4,\n",
       "         'MAHAFFEY': 3,\n",
       "         'MELFI (V.O.)': 2,\n",
       "         'KIDS': 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakerlist = []\n",
    "for speech in speeches:\n",
    "    speakerlist.append(speech.speaker.text)\n",
    "speakerlist\n",
    "Counter(speakerlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Soprano?',\n",
       " 'Have a seat.',\n",
       " 'My understanding from your family physician, Dr. Cusamano, is you collapsed? Were unable to breathe? Possibly a panic attack?',\n",
       " 'They said it was a panic attack — because all the neurological work and blood came back negative. They sent me here.',\n",
       " \"You don't agree you had a panic attack?\",\n",
       " 'How are you feeling now?',\n",
       " \"Now? Fine. I'm back at work.\",\n",
       " 'What line of work are you in?',\n",
       " 'Waste management consultant.',\n",
       " \"Look...it's impossible for me to talk to a psychiatrist.\",\n",
       " 'Any thoughts at all on why you blacked out?',\n",
       " \"I don't know. Stress/ maybe?\",\n",
       " 'Stress? About what?',\n",
       " \"That morning of the day I got sick? I'd been thinking: it's good to be in a thing from the ground floor. I came too late for that, I know. But lately I'm getting the feeling I might be in at the end. That the best is over.\",\n",
       " 'Many Americans, I think, feel this.',\n",
       " 'Take my father. He never reached the heights like me. But in ways he had it better. He had his people — they had their standards. They had pride. Today what do we .got?',\n",
       " 'Did you have this feeling of loss more acutely in the hours before you collapsed?',\n",
       " \"I dunno. Couple months before all this these two wild ducks had landed in my pool. Amazing. From Canada or someplace, I don't know. It was mating season.\",\n",
       " 'Yum. Yum.',\n",
       " \"My daughter's friend was there to drive my daughter, Meadow, to school.\",\n",
       " '(staring out window) Meadow, your father with those ducks.',\n",
       " 'Have something more than just cran- apple juice, ladies. You need brain food for school.',\n",
       " \"The male and female duck just made a home in your pool and 'did it'? Weird.\",\n",
       " \"(crosses with pastry) Girls, you want some of last night's sfogliatell'?\",\n",
       " 'Get out of here with that fat.',\n",
       " 'Oh, have a bite.',\n",
       " 'Wait — like Italian pastry is brain food?',\n",
       " 'Bon Jovi? Hello?',\n",
       " 'How do you stay so skinny, Mrs. Soprano?',\n",
       " \"Don't you worry. I'll make you a better ramp.\",\n",
       " 'Kids! Come here!',\n",
       " \"Look! They're trying to fly.\",\n",
       " '(bored, humoring) Nice, dad. National Geographic. [ETC]',\n",
       " \"It is so cool you're going to be able to come to Aspen with my family at Christmas. Last year at Aspen? I saw Skeet Ulrich. As close as from where you're sitting.\",\n",
       " 'Omigod.',\n",
       " \"My wife feels this friend of Meadow's is a bad influence.\",\n",
       " 'Miss Meadow, we made a deal — you keep your school grades up and you keep your curfew between now and Christmas — then you get to go.',\n",
       " '(edge) I know that.',\n",
       " 'Happy birthday, son.',\n",
       " \"You're going to be home tonight for Tommy Jr.'s party, right? (to his grunt) Birdman. Hello?\",\n",
       " \"I'll get home from work early.\",\n",
       " \"I wasn't talking about work.\",\n",
       " \"This isn't going to work. I can't talk about my personal life.\",\n",
       " \"It's hard for everybody.\",\n",
       " \"You don't understand.\",\n",
       " 'Finish telling me about the day you collapsed.',\n",
       " \"I rode to work with my nephew, Christopher...he's learning the business.\",\n",
       " \"He's an example of what I was saying before...\",\n",
       " 'You call whatsisname at Triboro Towers about the hauling contract?',\n",
       " \"I got home too late last night. I didn't want to wake the man up.\",\n",
       " \"You get up early this morning and call? He's always in the office at six.\",\n",
       " \"I was nauseous this morning. My mom told me I shouldn't even go in today.\",\n",
       " 'Bear in mind, this is a kid who just bought himself a 60,000 dollar Lexus.',\n",
       " \"It's that guy. Mahaffey.\",\n",
       " 'Get out.',\n",
       " 'Back there. See? With the boo-boo in red?',\n",
       " 'Back up.',\n",
       " 'There was an issue of an outstanding loan —',\n",
       " 'Let me stop you a second.',\n",
       " 'Sure.',\n",
       " 'I have no idea where this story is going...but there are a few ethical ground rules we should quickly get out of the way.',\n",
       " 'You said you were in waste management...',\n",
       " 'Recycle. The environment.',\n",
       " \"Dr. Cusamano, besides being your family physician, is also your next door neighbor. See what I'm saying?\",\n",
       " 'I get it. Yeah.',\n",
       " \"(dry mouth) What you tell me in here falls under doctor/patient confidentiality. Except — if I was, for example, to hear that a...say a...murder? was about to take place — (quickly) not that I'm saying — but, if.. Well, anything like that...where a patient tells me someone is going to be hurt? I'm supposed to go to the authorities. Technically.\",\n",
       " '(long beat) Oh.',\n",
       " \"I don't know what happened with this Mahaffey fellow. I'm just saying.\",\n",
       " 'I see.\\n\\n\\n\\n(beat) Nothing. We had coffee.',\n",
       " '(beat) Nothing. We had coffee.',\n",
       " 'Security!',\n",
       " \"My leg! It's broken! Oh fuck, oh fuck, the bone's coming through!\",\n",
       " \"I'll give you a fuckin' bone. Where's my money?\",\n",
       " \"I'll get the money!\",\n",
       " \"I know you'll get the — (sees Chris fussing over the car)\",\n",
       " 'The fuck you doing? Get over here.',\n",
       " \"I know you'll get the money. What you ought to fuckin' get is a fuckin' cork to put in your mouth.\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "speechlist2 = []\n",
    "for speech in speeches:\n",
    "    speechcopy = copy.copy(speech)\n",
    "    for speaker_tag in speechcopy.find_all(\"speaker\"):\n",
    "        speaker_tag.decompose()\n",
    "    #print(speechcopy, \"\\n$$\")\n",
    "    #print(speech)\n",
    "    #print()\n",
    "    speechlist2.append(speechcopy)\n",
    "\n",
    "# remove speaker tag\n",
    "speechlist2 = [speech.text.strip() for speech in speechlist2]\n",
    "speechlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>Mr. Soprano?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>Have a seat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>My understanding from your family physician, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>They said it was a panic attack — because all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>You don't agree you had a panic attack?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>I'll give you a fuckin' bone. Where's my money?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MAHAFFEY</td>\n",
       "      <td>I'll get the money!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>I know you'll get the — (sees Chris fussing ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>The fuck you doing? Get over here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>I know you'll get the money. What you ought to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker                                             speech\n",
       "0      MELFI                                       Mr. Soprano?\n",
       "1      MELFI                                       Have a seat.\n",
       "2      MELFI  My understanding from your family physician, D...\n",
       "3      TOMMY  They said it was a panic attack — because all ...\n",
       "4      MELFI            You don't agree you had a panic attack?\n",
       "..       ...                                                ...\n",
       "72     TOMMY    I'll give you a fuckin' bone. Where's my money?\n",
       "73  MAHAFFEY                                I'll get the money!\n",
       "74     TOMMY  I know you'll get the — (sees Chris fussing ov...\n",
       "75     TOMMY                 The fuck you doing? Get over here.\n",
       "76     TOMMY  I know you'll get the money. What you ought to...\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"speaker\": speakerlist, \"speech\": speechlist2})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker\n",
       "TOMMY           29\n",
       "MELFI           16\n",
       "TOMMY (V.O.)     7\n",
       "CARMELA          6\n",
       "HUNTER           5\n",
       "MEADOW           4\n",
       "CHRIS            4\n",
       "MAHAFFEY         3\n",
       "MELFI (V.O.)     2\n",
       "KIDS             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"speaker\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs. GPT-4o Mini response:\n",
    "\n",
    "```\n",
    "\n",
    "Here is the frequency list of the number of times each character spoke, derived from the screenplay: \n",
    "\n",
    "    TOMMY: 20\n",
    "    MELFI: 10\n",
    "    CARMELA: 7\n",
    "    CHRIS: 6\n",
    "    HUNTER: 4\n",
    "    MAHAFFEY: 4\n",
    "    MEADOW: 4\n",
    "    BIG PUSSY: 3\n",
    "    DAD (TOMMY SR.): 3\n",
    "    ARTHUR: 2\n",
    "    LIVIA: 2\n",
    "    FATHER PHIL: 2\n",
    "    SILVIO: 2\n",
    "    TOMMY JR.: 2\n",
    "    DICK BARONE: 1\n",
    "    CHARMAINE: 1\n",
    "    HERMAN: 1\n",
    "     \n",
    "\n",
    "This list counts each individual line spoken by the characters in the screenplay as a separate instance. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Words (by Speaker)\n",
    "\n",
    "### Python + spaCY v. GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group speech by speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>combined_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARMELA</td>\n",
       "      <td>Have something more than just cran- apple juic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHRIS</td>\n",
       "      <td>I got home too late last night. I didn't want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUNTER</td>\n",
       "      <td>(staring out window) Meadow, your father with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIDS</td>\n",
       "      <td>(bored, humoring) Nice, dad. National Geograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAHAFFEY</td>\n",
       "      <td>Security! My leg! It's broken! Oh fuck, oh fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEADOW</td>\n",
       "      <td>Get out of here with that fat. Wait — like Ita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>Mr. Soprano? Have a seat. My understanding fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MELFI (V.O.)</td>\n",
       "      <td>Many Americans, I think, feel this. Did you ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>They said it was a panic attack — because all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOMMY (V.O.)</td>\n",
       "      <td>That morning of the day I got sick? I'd been t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                                    combined_speech\n",
       "0       CARMELA  Have something more than just cran- apple juic...\n",
       "1         CHRIS  I got home too late last night. I didn't want ...\n",
       "2        HUNTER  (staring out window) Meadow, your father with ...\n",
       "3          KIDS  (bored, humoring) Nice, dad. National Geograph...\n",
       "4      MAHAFFEY  Security! My leg! It's broken! Oh fuck, oh fuc...\n",
       "5        MEADOW  Get out of here with that fat. Wait — like Ita...\n",
       "6         MELFI  Mr. Soprano? Have a seat. My understanding fro...\n",
       "7  MELFI (V.O.)  Many Americans, I think, feel this. Did you ha...\n",
       "8         TOMMY  They said it was a panic attack — because all ...\n",
       "9  TOMMY (V.O.)  That morning of the day I got sick? I'd been t..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'speaker' and concatenate speeches\n",
    "grouped_df = df.groupby('speaker')['speech'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Rename the 'speech' column if desired\n",
    "grouped_df.rename(columns={'speech': 'combined_speech'}, inplace=True)\n",
    "\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the text\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_words = []\n",
    "\n",
    "    # Process each text element in the list\n",
    "    #for text in text_list:\n",
    "        # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "        \n",
    "    # Lemmatize words and filter out stop words\n",
    "    for token in doc:\n",
    "        # Check if the token is a stop word or punctuation\n",
    "        if not token.is_stop and token.is_alpha:\n",
    "            lemmatized_words.append(token.lemma_.lower())\n",
    "\n",
    "    return lemmatized_words\n",
    "\n",
    "# Function to find the top N frequent words\n",
    "def top_n_frequent_words(word_list, n=5):\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(word_list)\n",
    "    \n",
    "    # Get the N most common words\n",
    "    return word_counts.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>combined_speech</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARMELA</td>\n",
       "      <td>Have something more than just cran- apple juic...</td>\n",
       "      <td>[apple, juice, lady, need, brain, food, school...</td>\n",
       "      <td>[(school, 2), (apple, 1), (juice, 1), (lady, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHRIS</td>\n",
       "      <td>I got home too late last night. I didn't want ...</td>\n",
       "      <td>[get, home, late, night, want, wake, man, naus...</td>\n",
       "      <td>[(boo, 2), (get, 1), (home, 1), (late, 1), (ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUNTER</td>\n",
       "      <td>(staring out window) Meadow, your father with ...</td>\n",
       "      <td>[stare, window, meadow, father, duck, male, fe...</td>\n",
       "      <td>[(duck, 2), (aspen, 2), (stare, 1), (window, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIDS</td>\n",
       "      <td>(bored, humoring) Nice, dad. National Geograph...</td>\n",
       "      <td>[bored, humor, nice, dad, national, geographic...</td>\n",
       "      <td>[(bored, 1), (humor, 1), (nice, 1), (dad, 1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAHAFFEY</td>\n",
       "      <td>Security! My leg! It's broken! Oh fuck, oh fuc...</td>\n",
       "      <td>[security, leg, break, oh, fuck, oh, fuck, bon...</td>\n",
       "      <td>[(oh, 2), (fuck, 2), (security, 1), (leg, 1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEADOW</td>\n",
       "      <td>Get out of here with that fat. Wait — like Ita...</td>\n",
       "      <td>[fat, wait, like, italian, pastry, brain, food...</td>\n",
       "      <td>[(fat, 1), (wait, 1), (like, 1), (italian, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MELFI</td>\n",
       "      <td>Mr. Soprano? Have a seat. My understanding fro...</td>\n",
       "      <td>[soprano, seat, understanding, family, physici...</td>\n",
       "      <td>[(say, 4), (tell, 3), (family, 2), (physician,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MELFI (V.O.)</td>\n",
       "      <td>Many Americans, I think, feel this. Did you ha...</td>\n",
       "      <td>[americans, think, feel, feeling, loss, acutel...</td>\n",
       "      <td>[(americans, 1), (think, 1), (feel, 1), (feeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOMMY</td>\n",
       "      <td>They said it was a panic attack — because all ...</td>\n",
       "      <td>[say, panic, attack, neurological, work, blood...</td>\n",
       "      <td>[(work, 4), (know, 3), (beat, 3), (fuckin, 3),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOMMY (V.O.)</td>\n",
       "      <td>That morning of the day I got sick? I'd been t...</td>\n",
       "      <td>[morning, day, get, sick, think, good, thing, ...</td>\n",
       "      <td>[(get, 2), (good, 2), (know, 2), (daughter, 2)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                                    combined_speech  \\\n",
       "0       CARMELA  Have something more than just cran- apple juic...   \n",
       "1         CHRIS  I got home too late last night. I didn't want ...   \n",
       "2        HUNTER  (staring out window) Meadow, your father with ...   \n",
       "3          KIDS  (bored, humoring) Nice, dad. National Geograph...   \n",
       "4      MAHAFFEY  Security! My leg! It's broken! Oh fuck, oh fuc...   \n",
       "5        MEADOW  Get out of here with that fat. Wait — like Ita...   \n",
       "6         MELFI  Mr. Soprano? Have a seat. My understanding fro...   \n",
       "7  MELFI (V.O.)  Many Americans, I think, feel this. Did you ha...   \n",
       "8         TOMMY  They said it was a panic attack — because all ...   \n",
       "9  TOMMY (V.O.)  That morning of the day I got sick? I'd been t...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [apple, juice, lady, need, brain, food, school...   \n",
       "1  [get, home, late, night, want, wake, man, naus...   \n",
       "2  [stare, window, meadow, father, duck, male, fe...   \n",
       "3  [bored, humor, nice, dad, national, geographic...   \n",
       "4  [security, leg, break, oh, fuck, oh, fuck, bon...   \n",
       "5  [fat, wait, like, italian, pastry, brain, food...   \n",
       "6  [soprano, seat, understanding, family, physici...   \n",
       "7  [americans, think, feel, feeling, loss, acutel...   \n",
       "8  [say, panic, attack, neurological, work, blood...   \n",
       "9  [morning, day, get, sick, think, good, thing, ...   \n",
       "\n",
       "                                           top_words  \n",
       "0  [(school, 2), (apple, 1), (juice, 1), (lady, 1...  \n",
       "1  [(boo, 2), (get, 1), (home, 1), (late, 1), (ni...  \n",
       "2  [(duck, 2), (aspen, 2), (stare, 1), (window, 1...  \n",
       "3  [(bored, 1), (humor, 1), (nice, 1), (dad, 1), ...  \n",
       "4  [(oh, 2), (fuck, 2), (security, 1), (leg, 1), ...  \n",
       "5  [(fat, 1), (wait, 1), (like, 1), (italian, 1),...  \n",
       "6  [(say, 4), (tell, 3), (family, 2), (physician,...  \n",
       "7  [(americans, 1), (think, 1), (feel, 1), (feeli...  \n",
       "8  [(work, 4), (know, 3), (beat, 3), (fuckin, 3),...  \n",
       "9  [(get, 2), (good, 2), (know, 2), (daughter, 2)...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[\"lemmas\"] = grouped_df[\"combined_speech\"].apply(lemmatize_text)\n",
    "grouped_df[\"top_words\"] = grouped_df[\"lemmas\"].apply(top_n_frequent_words, n=5)\n",
    "grouped_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 word frequency list as generated by GPT-4o Mini:\n",
    "\n",
    "*Prompt:*\n",
    "```\n",
    "Create a frequency list of words to aid the analysis of this screenplay. First, extract only the spoken text, indicated by the <l> tag within each <sp> tag. Second, from this spoken text, create a frequency list of the top 5 words spoken by each speaker, but only after removing all stop words.\n",
    "```\n",
    "\n",
    "*Response:*\n",
    "\n",
    "\n",
    "GPT-4o Mini (Cloud, Paid, $) 2024-07-18\n",
    "Today at 4:15 PM\n",
    " \n",
    "\n",
    "Here's the frequency list of the top 5 words spoken by each character, after removing stop words: \n",
    "\n",
    "**TOMMY** \n",
    "\n",
    "    money: 5\n",
    "    ducks: 3\n",
    "    work: 3\n",
    "    father: 3\n",
    "    feel: 3\n",
    "     \n",
    "\n",
    "**MELFI** \n",
    "\n",
    "    panic: 3\n",
    "    understanding: 2\n",
    "    attack: 2\n",
    "    work: 2\n",
    "    stress: 2\n",
    "     \n",
    "\n",
    "**CARMELA** \n",
    "\n",
    "    Meadow: 4\n",
    "    school: 3\n",
    "    grades: 2\n",
    "    father: 2\n",
    "    ziti: 2\n",
    "     \n",
    "\n",
    "**CHRIS** \n",
    "\n",
    "    Mahaffey: 3\n",
    "    business: 3\n",
    "    money: 3\n",
    "    call: 2\n",
    "    family: 2\n",
    "     \n",
    "\n",
    "**HUNTER** \n",
    "\n",
    "    Aspen: 2\n",
    "    cool: 2\n",
    "    think: 2\n",
    "    fun: 2\n",
    "    vacation: 2\n",
    "     \n",
    "\n",
    "**MAHAFFEY** \n",
    "\n",
    "    sorry: 3\n",
    "    money: 3\n",
    "    broken: 2\n",
    "    leg: 2\n",
    "    company: 2\n",
    "     \n",
    "\n",
    "**MEADOW** \n",
    "\n",
    "    dad: 3\n",
    "    think: 2\n",
    "    stupid: 2\n",
    "    school: 2\n",
    "    trip: 2\n",
    "     \n",
    "\n",
    "**BIG PUSSY** \n",
    "\n",
    "    business: 2\n",
    "    Kolar: 2\n",
    "    money: 2\n",
    "    good: 2\n",
    "    family: 2\n",
    "     \n",
    "\n",
    "**ARTHUR** \n",
    "\n",
    "    help: 2\n",
    "    vacation: 2\n",
    "    deal: 2\n",
    "    restaurant: 2\n",
    "    days: 2\n",
    "     \n",
    "\n",
    "**LIVIA** \n",
    "\n",
    "    home: 2\n",
    "    nursing: 2\n",
    "    mother: 2\n",
    "    day: 2\n",
    "    people: 2\n",
    "     \n",
    "\n",
    "**FATHER PHIL** \n",
    "\n",
    "    damn: 2\n",
    "    night: 2\n",
    "    incredible: 2\n",
    "    just: 2\n",
    "    think: 2\n",
    "     \n",
    "\n",
    "**SILVIO** \n",
    "\n",
    "    night: 2\n",
    "    family: 2\n",
    "    go: 2\n",
    "    talk: 2\n",
    "    people: 2\n",
    "     \n",
    "\n",
    "**TOMMY JR.** \n",
    "\n",
    "    grandma: 2\n",
    "    happy: 2\n",
    "    home: 2\n",
    "    dad: 2\n",
    "    birthday: 2\n",
    "     \n",
    "\n",
    "**DICK BARONE** \n",
    "\n",
    "    contract: 1\n",
    "    money: 1\n",
    "    business: 1\n",
    "    call: 1\n",
    "    good: 1\n",
    "     \n",
    "\n",
    "**CHARMAINE** \n",
    "\n",
    "    gift: 1\n",
    "    stay: 1\n",
    "    home: 1\n",
    "    better: 1\n",
    "    anything: 1\n",
    "     \n",
    "\n",
    "**HERMAN** \n",
    "\n",
    "    chance: 1\n",
    "    money: 1\n",
    "    problem: 1\n",
    "    time: 1\n",
    "    feelings: 1\n",
    "     \n",
    "\n",
    "This frequency list highlights the common words spoken by each character, providing insights into their dialogue patterns and focal points in the screenplay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Information for each Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = divs[4]\n",
    "type(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene_info(tag):\n",
    "    \"\"\"\n",
    "    Reads in a bs4 \"div tag\" containing a scene in a screenplay (using the tags: head = name of scene; stage = stage directions, speaker = for the name of each speaker)\n",
    "\n",
    "    Returns a dictionary containing the scene name, initial stage instructions (ignores any 2nd or 3rd stage instructions), and speaker count for each scene\n",
    "    \"\"\"\n",
    "    if tag.name != \"div\":\n",
    "        print(\"error, not a div tag!\")\n",
    "        return None, None, None\n",
    "    head = tag.find(\"head\")\n",
    "    if head is not None:\n",
    "        head = head.text\n",
    "    stage = tag.find(\"stage\")\n",
    "    if stage is not None:\n",
    "        stage = stage.text\n",
    "\n",
    "    speakerlist = []\n",
    "    if tag.find(\"speaker\"):\n",
    "        speakers = tag.find_all(\"speaker\")\n",
    "        speakerlist = [speaker.text for speaker in speakers]\n",
    "    speakerlist\n",
    "\n",
    "    speaker_ct = Counter(speakerlist)\n",
    "\n",
    "    return {\"head\": head, \"stage\": stage, \"speaker_ct\": speaker_ct}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>stage</th>\n",
       "      <th>speaker_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INT. DR. MELFI'S WAITING ROOM - DAY</td>\n",
       "      <td>THOMAS SOPRANO, 40, sits and waits. Uneasily. ...</td>\n",
       "      <td>{'MELFI': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INT. DR. MELFI'S OFFICE - DAY</td>\n",
       "      <td>Melfi gestures Tommy to a choice of seating.</td>\n",
       "      <td>{'MELFI': 7, 'TOMMY': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXT. SOPRANO HOUSE - DAWN</td>\n",
       "      <td>split-level. New Jersey. The only thing distin...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INT. SOPRANO HOUSE - BEDROOM - DAWN</td>\n",
       "      <td>TOMMY'S EYE slams open from sleep. He stares s...</td>\n",
       "      <td>{'TOMMY (V.O.)': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXT. SOPRANO HOUSE - DAY</td>\n",
       "      <td>Bathrobed Tommy reads his morning paper in the...</td>\n",
       "      <td>{'MELFI (V.O.)': 2, 'TOMMY (V.O.)': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  head  \\\n",
       "0  INT. DR. MELFI'S WAITING ROOM - DAY   \n",
       "1        INT. DR. MELFI'S OFFICE - DAY   \n",
       "2            EXT. SOPRANO HOUSE - DAWN   \n",
       "3  INT. SOPRANO HOUSE - BEDROOM - DAWN   \n",
       "4             EXT. SOPRANO HOUSE - DAY   \n",
       "\n",
       "                                               stage  \\\n",
       "0  THOMAS SOPRANO, 40, sits and waits. Uneasily. ...   \n",
       "1       Melfi gestures Tommy to a choice of seating.   \n",
       "2  split-level. New Jersey. The only thing distin...   \n",
       "3  TOMMY'S EYE slams open from sleep. He stares s...   \n",
       "4  Bathrobed Tommy reads his morning paper in the...   \n",
       "\n",
       "                               speaker_ct  \n",
       "0                            {'MELFI': 1}  \n",
       "1                {'MELFI': 7, 'TOMMY': 5}  \n",
       "2                                      {}  \n",
       "3                     {'TOMMY (V.O.)': 1}  \n",
       "4  {'MELFI (V.O.)': 2, 'TOMMY (V.O.)': 1}  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divs = body.find_all(\"div\")\n",
    "\n",
    "sceneinfodict_list = []\n",
    "\n",
    "for div in divs:\n",
    "    sceneinfodict_list.append(get_scene_info(div))\n",
    "\n",
    "scene_df = pd.DataFrame(sceneinfodict_list)\n",
    "scene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations to make:\n",
    "1. when and how often each speaker speaks\n",
    "2. sentiment analysis by speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Asking Questions of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
